{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F3r8aa3pBigj"
   },
   "source": [
    "# Tarea para el Hogar 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nBm4ktHUBmZt"
   },
   "source": [
    "Esta Tarea para el Hogar 02 se entrega el final de la segunda clase\n",
    "<br> se espera de usted que intente avanzar con los desafios propuestos y que los traiga terminados para la Clase 03, ya que se analizarán los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK-M04ElCESC"
   },
   "source": [
    "##  1. Ensembles de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biPYxgobCOSS"
   },
   "source": [
    "Vea el siguiente video [BBC - The Code - The Wisdom of the Crowd](https://www.youtube.com/watch?v=iOucwX7Z1HU)    ( 5 min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBszBRyNCcjp"
   },
   "source": [
    "Lea los siguientes artículos\n",
    "\n",
    "\n",
    "*   [The Wisdom of Crowds (Vox Populi) by Francis Galton](https://www.all-about-psychology.com/the-wisdom-of-crowds.html)  (10 min)\n",
    "*   [A Gentle Introduction to Ensemble Learning](https://machinelearningmastery.com/what-is-ensemble-learning/)  (10 min)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7SebtV2lpHQ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQcY8u2MDSLT"
   },
   "source": [
    "##  2.  Zero2Hero   primera parte\n",
    "Se han lanzado los primeros fascículos coleccionables llamados \"from Zero to Hero\" que muy detalladamente, paso a paso enseñan todo lo necesario de R para entender los scripts oficiales de la asignatura.\n",
    "Están en el repositorio oficial de la asignatura, carpeta  **src/zero2hero**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GcO0OSiIEAGy"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6MStcyn0EBdT"
   },
   "source": [
    "## 3.  Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gM8RKXDgEIY0"
   },
   "source": [
    "Busque en internet el precido significado de los hiperparámetros de la librería **rpart**  que está implementando el algoritmo **CART**  Classification and Regression Trees  propuesto en el año 1984 por Leo Brieman:\n",
    "\n",
    "*   cp\n",
    "*   maxdepth\n",
    "*   minsplit\n",
    "*   minbucket\n",
    "\n",
    "Entienda que valores es razonable tome cada hiperparámetro,  en particular profundice en el hiperparámetro  **cp**  y la posibilidad que tome valores negativos.  Es válido consultar a su amigo de *capacidades especiales*  ChatGPT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_k7eT3HIFy9y"
   },
   "source": [
    "En las siguientes celdas a un notebook incompleto, un esqueleto de codigo brindado a modo de facilitarle la tarea de codeo y permitir que su valiosa cognición se concentre temas conceptuales de Ciencia de Datos\n",
    "\n",
    "Modifiquelo agregando loops para que recorra TODOS los hiperparámetros de rpart  < cp, maxdepth, minsplit, minbucket >, y luego póngalo a correr. Recuerde cambiar por SU semilla\n",
    "Tenga muy presente la granularidad que eligirá para cada hiperparámetro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmLygy1TYPfg"
   },
   "source": [
    "### Seteo del ambiente en Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OikOm5K2YU3X"
   },
   "source": [
    "Esta parte se debe correr con el runtime en Python3\n",
    "<br>Ir al menu, Runtime -> Change Runtime Tipe -> Runtime type ->  **Python 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fmV5LyZdFyI"
   },
   "source": [
    "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilEZ-bE2VybW",
    "outputId": "b1125aab-758d-4cce-c966-5d378171a64e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/.drive\n"
     ]
    }
   ],
   "source": [
    "# primero establecer el Runtime de Python 3\n",
    "from google.colab import drive\n",
    "drive.mount('/content/.drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ilaKtqWldeWg"
   },
   "source": [
    "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
    "\n",
    "<br>los siguientes comando estan en shell script de Linux\n",
    "*   Crear las carpetas en el Google Drive\n",
    "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
    "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8dQFI5QYCFa",
    "outputId": "23e67579-e1db-4165-ecb8-1b583532106e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%shell\n",
    "\n",
    "mkdir -p \"/content/.drive/My Drive/dm\"\n",
    "mkdir -p \"/content/buckets\"\n",
    "ln -s \"/content/.drive/My Drive/dm\" /content/buckets/b1\n",
    "\n",
    "mkdir -p ~/.kaggle\n",
    "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
    "chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "\n",
    "mkdir -p /content/buckets/b1/exp\n",
    "mkdir -p /content/buckets/b1/datasets\n",
    "mkdir -p /content/datasets\n",
    "\n",
    "\n",
    "\n",
    "archivo_origen=\"https://storage.googleapis.com/open-courses/itba2025-8d0a/dataset_pequeno.csv\"\n",
    "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
    "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
    "\n",
    "if ! test -f $archivo_destino_bucket; then\n",
    "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
    "fi\n",
    "\n",
    "\n",
    "if ! test -f $archivo_destino; then\n",
    "  cp  $archivo_destino_bucket  $archivo_destino\n",
    "fi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SE94XRhWsxkX"
   },
   "source": [
    "limpio el ambiente de R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "oZG_4br6szlT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A matrix: 2 × 6 of type dbl</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>used</th><th scope=col>(Mb)</th><th scope=col>gc trigger</th><th scope=col>(Mb)</th><th scope=col>max used</th><th scope=col>(Mb)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Ncells</th><td> 803613</td><td>43.0</td><td> 1439377</td><td> 76.9</td><td>  1439377</td><td> 76.9</td></tr>\n",
       "\t<tr><th scope=row>Vcells</th><td>1506546</td><td>11.5</td><td>90542964</td><td>690.8</td><td>113153819</td><td>863.3</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A matrix: 2 × 6 of type dbl\n",
       "\\begin{tabular}{r|llllll}\n",
       "  & used & (Mb) & gc trigger & (Mb) & max used & (Mb)\\\\\n",
       "\\hline\n",
       "\tNcells &  803613 & 43.0 &  1439377 &  76.9 &   1439377 &  76.9\\\\\n",
       "\tVcells & 1506546 & 11.5 & 90542964 & 690.8 & 113153819 & 863.3\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A matrix: 2 × 6 of type dbl\n",
       "\n",
       "| <!--/--> | used | (Mb) | gc trigger | (Mb) | max used | (Mb) |\n",
       "|---|---|---|---|---|---|---|\n",
       "| Ncells |  803613 | 43.0 |  1439377 |  76.9 |   1439377 |  76.9 |\n",
       "| Vcells | 1506546 | 11.5 | 90542964 | 690.8 | 113153819 | 863.3 |\n",
       "\n"
      ],
      "text/plain": [
       "       used    (Mb) gc trigger (Mb)  max used  (Mb) \n",
       "Ncells  803613 43.0  1439377    76.9   1439377  76.9\n",
       "Vcells 1506546 11.5 90542964   690.8 113153819 863.3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# limpio la memoria\n",
    "rm(list=ls(all.names=TRUE)) # remove all objects\n",
    "gc(full=TRUE, verbose=FALSE) # garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JO-12d7YHkWy",
    "outputId": "9d7af7a7-86b4-4bd4-85a3-57373481cf1b"
   },
   "outputs": [],
   "source": [
    "# cargo las librerias que necesito\n",
    "require(\"data.table\")\n",
    "require(\"rpart\")\n",
    "require(\"parallel\")\n",
    "if (!require(\"primes\")) install.packages(\"primes\")\n",
    "require(\"primes\")\n",
    "options(scipen = 999, digits = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MclPEJ6Q8Bp"
   },
   "source": [
    "Aqui debe poner SU semiila primigenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "Vt5fC6bWHu5r"
   },
   "outputs": [],
   "source": [
    "PARAM <- list()\n",
    "# reemplazar por su primer semilla\n",
    "PARAM$semilla_primigenia <- 500057\n",
    "PARAM$qsemillas <- 1\n",
    "\n",
    "PARAM$training_pct <- 70L  # entre  1L y 99L\n",
    "\n",
    "# elegir SU dataset comentando/ descomentando\n",
    "PARAM$dataset_nom <- \"~/datasets/dataset_pequeno.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Z1dchsrWH4MD"
   },
   "outputs": [],
   "source": [
    "# particionar agrega una columna llamada fold a un dataset\n",
    "#  que consiste en una particion estratificada segun agrupa\n",
    "# particionar( data=dataset, division=c(70,30), agrupa=clase_ternaria, seed=semilla)\n",
    "#   crea una particion 70, 30\n",
    "\n",
    "particionar <- function(data, division, agrupa = \"\", campo = \"fold\", start = 1, seed = NA) {\n",
    "  if (!is.na(seed)) set.seed(seed)\n",
    "\n",
    "  bloque <- unlist(mapply(function(x, y) {\n",
    "    rep(y, x)\n",
    "  }, division, seq(from = start, length.out = length(division))))\n",
    "\n",
    "  data[, (campo) := sample(rep(bloque, ceiling(.N / length(bloque))))[1:.N],\n",
    "    by = agrupa\n",
    "  ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "xsHwS1CzIA70"
   },
   "outputs": [],
   "source": [
    "ArbolEstimarGanancia <- function(semilla, training_pct, param_basicos) {\n",
    "  # particiono estratificadamente el dataset\n",
    "  particionar(dataset,\n",
    "    division = c(training_pct, 100L -training_pct),\n",
    "    agrupa = \"clase_ternaria\",\n",
    "    seed = semilla # aqui se usa SU semilla\n",
    "  )\n",
    "\n",
    "  # genero el modelo\n",
    "  # predecir clase_ternaria a partir del resto\n",
    "  modelo <- rpart(\"clase_ternaria ~ .\",\n",
    "    data = dataset[fold == 1], # fold==1  es training,  el 70% de los datos\n",
    "    xval = 0,\n",
    "    control = param_basicos\n",
    "  ) # aqui van los parametros del arbol\n",
    "\n",
    "  # aplico el modelo a los datos de testing\n",
    "  prediccion <- predict(modelo, # el modelo que genere recien\n",
    "    dataset[fold == 2], # fold==2  es testing, el 30% de los datos\n",
    "    type = \"prob\"\n",
    "  ) # type= \"prob\"  es que devuelva la probabilidad\n",
    "\n",
    "  # prediccion es una matriz con TRES columnas,\n",
    "  #  llamadas \"BAJA+1\", \"BAJA+2\"  y \"CONTINUA\"\n",
    "  # cada columna es el vector de probabilidades\n",
    "\n",
    "\n",
    "  # calculo la ganancia en testing  qu es fold==2\n",
    "  ganancia_test <- dataset[\n",
    "    fold == 2,\n",
    "    sum(ifelse(prediccion[, \"BAJA+2\"] > 0.025,\n",
    "      ifelse(clase_ternaria == \"BAJA+2\", 117000, -3000),\n",
    "      0\n",
    "    ))\n",
    "  ]\n",
    "\n",
    "  # escalo la ganancia como si fuera todo el dataset\n",
    "  ganancia_test_normalizada <- ganancia_test / (( 100 - PARAM$training_pct ) / 100 )\n",
    "    # Forzar formato no científico\n",
    "  ganancia_test_normalizada <- as.numeric(format(ganancia_test_normalizada, scientific = FALSE))\n",
    "\n",
    "  return(\n",
    "    c( list(\"semilla\" = semilla),\n",
    "      param_basicos,\n",
    "      list( \"ganancia_test\" = ganancia_test_normalizada )\n",
    "     )\n",
    "  )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "BvBVOuhqIEjD"
   },
   "outputs": [],
   "source": [
    "ArbolesMontecarlo <- function(semillas, param_basicos) {\n",
    "\n",
    "  # la funcion mcmapply  llama a la funcion ArbolEstimarGanancia\n",
    "  #  tantas veces como valores tenga el vector  PARAM$semillas\n",
    "  salida <- mcmapply(ArbolEstimarGanancia,\n",
    "    semillas, # paso el vector de semillas\n",
    "    MoreArgs = list(PARAM$training_pct, param_basicos), # aqui paso el segundo parametro\n",
    "    SIMPLIFY = FALSE,\n",
    "    mc.cores = detectCores()\n",
    "  )\n",
    "\n",
    "  return(salida)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "L-DOGHOjIG7G"
   },
   "outputs": [],
   "source": [
    "# carpeta de trabajo\n",
    "# por fabor cambiar numero de experimento si se cambia el loop principal\n",
    "setwd(\"/content/buckets/b1/exp\")\n",
    "experimento <- \"HT2900\"\n",
    "dir.create(experimento, showWarnings=FALSE)\n",
    "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "NM-mrLWcIPo6"
   },
   "outputs": [],
   "source": [
    "# lectura del dataset\n",
    "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")\n",
    "\n",
    "# trabajo solo con los datos con clase, es decir 202107\n",
    "dataset <- dataset[clase_ternaria != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "tSlY0EcgIWdi"
   },
   "outputs": [],
   "source": [
    "\n",
    "# genero numeros primos\n",
    "primos <- generate_primes(min = 100000, max = 1000000)\n",
    "set.seed(PARAM$semilla_primigenia) # inicializo\n",
    "# me quedo con PARAM$qsemillas   semillas\n",
    "PARAM$semillas <- sample(primos, PARAM$qsemillas )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xxCAwIKyIaTl",
    "outputId": "ffe1bcca-e69f-47fe-81a1-562fd3f211a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0"
      ],
      "text/latex": [
       "0"
      ],
      "text/markdown": [
       "0"
      ],
      "text/plain": [
       "[1] 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# genero la data.table donde van los resultados detallados del Grid Search\n",
    "# un registro para cada combinacion de < semilla, parametros >\n",
    "\n",
    "if(file.exists(\"gridsearch_detalle.txt\")){\n",
    "  tb_grid_search_detalle <- fread(\"gridsearch_detalle.txt\")\n",
    "}else{\n",
    "  tb_grid_search_detalle <- data.table(\n",
    "    semilla = integer(),\n",
    "    cp = numeric(),\n",
    "    maxdepth = integer(),\n",
    "   minsplit = integer(),\n",
    "    minbucket = integer(),\n",
    "    ganancia_test = numeric()\n",
    "  )\n",
    "}\n",
    "\n",
    "nrow( tb_grid_search_detalle )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAuGBNL8IkOD"
   },
   "source": [
    "Esta es la parte del código que usted debe expandir a TODOS los hiperparámetros de rpart,\n",
    "<br>ya que actualmente apenas recorre  maxdepth y  minsplit  dejando fijos  cp=-0.5  y minbucket=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ipLHm3STIfmb",
    "outputId": "af596d3e-3cc7-4f7f-df46-7ec6104dc284",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3   52970000 \n",
      "4   52970000 \n",
      "5   52740000 \n",
      "6   52470000 \n",
      "7   52470000 \n",
      "8   52970000 \n",
      "9   52970000 \n",
      "10   52740000 \n",
      "11   52470000 \n",
      "12   52470000 \n",
      "13   52970000 \n",
      "14   52970000 \n",
      "15   52740000 \n",
      "16   52470000 \n",
      "17   52470000 \n",
      "18   52970000 \n",
      "19   52970000 \n",
      "20   52740000 \n",
      "21   52470000 \n",
      "22   52470000 \n",
      "23   52970000 \n",
      "24   52970000 \n",
      "25   52740000 \n",
      "26   52470000 \n",
      "27   52470000 \n",
      "28   52970000 \n",
      "29   52970000 \n",
      "30   52740000 \n",
      "31   52470000 \n",
      "32   52470000 \n",
      "33   52970000 \n",
      "34   52970000 \n",
      "35   52740000 \n",
      "36   52470000 \n",
      "37   52470000 \n",
      "38   52970000 \n",
      "39   52970000 \n",
      "40   52740000 \n",
      "41   52470000 \n",
      "42   52470000 \n",
      "43   52970000 \n",
      "44   52970000 \n",
      "45   52740000 \n",
      "46   52470000 \n",
      "47   52470000 \n",
      "48   52970000 \n",
      "49   52970000 \n",
      "50   52740000 \n",
      "51   52470000 \n",
      "52   52470000 \n",
      "53   52970000 \n",
      "54   52970000 \n",
      "55   52740000 \n",
      "56   52470000 \n",
      "57   52470000 \n",
      "58   52970000 \n",
      "59   52970000 \n",
      "60   52740000 \n",
      "61   52470000 \n",
      "62   52470000 \n",
      "63   52970000 \n",
      "64   52970000 \n",
      "65   52740000 \n",
      "66   52470000 \n",
      "67   52470000 \n",
      "71   52470000 \n",
      "72   52470000 \n",
      "73   52970000 \n",
      "74   52970000 \n",
      "75   52740000 \n",
      "76   52470000 \n",
      "77   52470000 \n",
      "78   52970000 \n",
      "79   52970000 \n",
      "80   52470000 \n",
      "81   52470000 \n",
      "82   52970000 \n",
      "83   52970000 \n",
      "84   52470000 \n",
      "85   52470000 \n",
      "86   52970000 \n",
      "87   52970000 \n",
      "88   52660000 \n",
      "89   52660000 \n",
      "90   53160000 \n",
      "91   52660000 \n",
      "92   52660000 \n",
      "93   53160000 \n",
      "94   52660000 \n",
      "95   52660000 \n",
      "96   53160000 \n",
      "97   52660000 \n",
      "98   52660000 \n",
      "99   52660000 \n",
      "100   52660000 \n",
      "101   52660000 \n",
      "102   52660000 \n",
      "103   52660000 \n",
      "104   52660000 \n",
      "105   52660000 \n",
      "106   51080000 \n",
      "107   51140000 \n",
      "108   50740000 \n",
      "109   51280000 \n",
      "110   53560000 \n",
      "111   51080000 \n",
      "112   51140000 \n",
      "113   50740000 \n",
      "114   51280000 \n",
      "117   51140000 \n",
      "118   50740000 \n",
      "119   51280000 \n",
      "120   53560000 \n",
      "121   51360000 \n",
      "122   51420000 \n",
      "123   50950000 \n",
      "124   51280000 \n",
      "125   53940000 \n",
      "126   51360000 \n",
      "127   51420000 \n",
      "128   50950000 \n",
      "129   51280000 \n",
      "130   53940000 \n",
      "131   51360000 \n",
      "132   51420000 \n",
      "133   50950000 \n",
      "134   51280000 \n",
      "137   52200000 \n",
      "138   50690000 \n",
      "139   51280000 \n",
      "140   53940000 \n",
      "141   51390000 \n",
      "142   52200000 \n",
      "143   50690000 \n",
      "144   51280000 \n",
      "145   53940000 \n",
      "146   51390000 \n",
      "147   52200000 \n",
      "148   50690000 \n",
      "149   51280000 \n",
      "150   53940000 \n",
      "151   51390000 \n",
      "152   52200000 \n",
      "153   50690000 \n",
      "154   50410000 \n",
      "155   52540000 \n",
      "156   51390000 \n",
      "157   52200000 \n",
      "160   52540000 \n",
      "161   51390000 \n",
      "162   52200000 \n",
      "163   50690000 \n",
      "164   50410000 \n",
      "165   52540000 \n",
      "166   51450000 \n",
      "167   51560000 \n",
      "168   50080000 \n",
      "169   50730000 \n",
      "170   52920000 \n",
      "171   51450000 \n",
      "172   51560000 \n",
      "173   50080000 \n",
      "174   50730000 \n",
      "175   52920000 \n",
      "176   51450000 \n",
      "177   51560000 \n",
      "180   52920000 \n",
      "181   51450000 \n",
      "182   51560000 \n",
      "183   50080000 \n",
      "184   50730000 \n",
      "185   51450000 \n",
      "186   51560000 \n",
      "187   50080000 \n",
      "188   50730000 \n",
      "189   51450000 \n",
      "190   51560000 \n",
      "191   50080000 \n",
      "192   50730000 \n",
      "193   51660000 \n",
      "194   51750000 \n",
      "195   50100000 \n",
      "196   51660000 \n",
      "197   51750000 \n",
      "198   50100000 \n",
      "199   51660000 \n",
      "200   51750000 \n",
      "201   50100000 \n",
      "204   51030000 \n",
      "205   51510000 \n",
      "206   51030000 \n",
      "207   51510000 \n",
      "208   51190000 \n",
      "209   51190000 \n",
      "210   51190000 \n",
      "211   50580000 \n",
      "212   49160000 \n",
      "213   51540000 \n",
      "214   47200000 \n",
      "215   51430000 \n",
      "216   50580000 \n",
      "217   49160000 \n",
      "218   51540000 \n",
      "219   47200000 \n",
      "221   50580000 \n",
      "222   49160000 \n",
      "223   51540000 \n",
      "224   47200000 \n",
      "225   51430000 \n",
      "226   50860000 \n",
      "227   49440000 \n",
      "228   51750000 \n",
      "229   47200000 \n",
      "230   51810000 \n",
      "231   50860000 \n",
      "232   49440000 \n",
      "233   51750000 \n",
      "234   47200000 \n",
      "235   51810000 \n",
      "238   51750000 \n",
      "239   47200000 \n",
      "240   51810000 \n",
      "241   50880000 \n",
      "242   49970000 \n",
      "243   51450000 \n",
      "244   48140000 \n",
      "245   52060000 \n",
      "246   50880000 \n",
      "247   49970000 \n",
      "248   51450000 \n",
      "249   48140000 \n",
      "250   52060000 \n",
      "251   50880000 \n",
      "253   51450000 \n",
      "254   48140000 \n",
      "255   52060000 \n",
      "256   47840000 \n",
      "258   51560000 \n",
      "259   47430000 \n",
      "260   52560000 \n",
      "263   51560000 \n",
      "264   47430000 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# itero por los loops anidados para cada hiperparametro\n",
    "iter <- 0\n",
    "\n",
    "for (vmax_depth in c(4, 6, 8, 10, 12)) {\n",
    "  for (vmin_split in c(1000, 800, 600, 400, 200, 100, 50, 20, 10)) {\n",
    "    for (cp in c(-0.1, -0.5, -1)) {\n",
    "      for (vmin_bucket in c(5, 10, 20, 50, 100)) {\n",
    "    # notar como se agrega\n",
    "    \n",
    "    # ---- NUEVA CONDICIÓN: salta combinaciones inválidas ----\n",
    "        if (vmin_split / vmin_bucket < 2) next     \n",
    "          \n",
    "        iter <- iter + 1\n",
    "        if( iter*PARAM$qsemillas < nrow(tb_grid_search_detalle)+1 ) next\n",
    "\n",
    "    # vminsplit  minima cantidad de registros en un nodo para hacer el split\n",
    "    param_basicos <- list(\n",
    "      \"cp\" = cp, # complejidad minima\n",
    "      \"maxdepth\" = vmax_depth, # profundidad máxima del arbol\n",
    "      \"minsplit\" = vmin_split, # tamaño minimo de nodo para hacer split\n",
    "      \"minbucket\" = vmin_bucket # minima cantidad de registros en una hoja\n",
    "    )\n",
    "\n",
    "    # Un solo llamado, con la semilla 17\n",
    "    ganancias <- ArbolesMontecarlo(PARAM$semillas, param_basicos)\n",
    "\n",
    "    \n",
    "    cat( iter, \" \", ganancias[[1]]$ganancia_test, \"\\n\" )\n",
    "    flush.console()\n",
    "          \n",
    "    # agrego a la tabla\n",
    "    tb_grid_search_detalle <- rbindlist(\n",
    "      list( tb_grid_search_detalle,\n",
    "            rbindlist(ganancias) )\n",
    "       )\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  # grabo cada vez TODA la tabla en el loop mas externo\n",
    "  fwrite( tb_grid_search_detalle,\n",
    "          file = \"gridsearch_detalle.txt\",\n",
    "          sep = \"\\t\" )\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZaSqYBxiDFu"
   },
   "outputs": [],
   "source": [
    "fwrite( tb_grid_search_detalle,\n",
    "   file = \"gridsearch_detalle.txt\",\n",
    "   sep = \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STp0duM-RYVJ"
   },
   "outputs": [],
   "source": [
    "# cantidad de registros de la tabla\n",
    "nrow(tb_grid_search_detalle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7fhk_H0iNez"
   },
   "outputs": [],
   "source": [
    "# muestro la tabla\n",
    "tb_grid_search_detalle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DjCxtx8bIsgl"
   },
   "outputs": [],
   "source": [
    "# genero y grabo el resumen\n",
    "tb_grid_search <- tb_grid_search_detalle[,\n",
    "  list( \"ganancia_mean\" = mean(ganancia_test),\n",
    "    \"qty\" = .N ),\n",
    "  list( cp, maxdepth, minsplit, minbucket )\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LU29UhL1Ivg5"
   },
   "outputs": [],
   "source": [
    "# ordeno descendente por ganancia\n",
    "setorder( tb_grid_search, -ganancia_mean )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-EjGY7aIyWL"
   },
   "outputs": [],
   "source": [
    "# veo los 10 mejores hiperparámetros\n",
    "tb_grid_search[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3S-I2PTI5ZE"
   },
   "outputs": [],
   "source": [
    "# genero un id a la tabla\n",
    "tb_grid_search[, id := .I ]\n",
    "\n",
    "fwrite( tb_grid_search,\n",
    "  file = \"gridsearch.txt\",\n",
    "  sep = \"\\t\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1rYHk1YkI_9k"
   },
   "source": [
    "# 4.  Análisis de resultados de Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTJgPhMWJHTk"
   },
   "source": [
    "La salida de la corrida anterior queda en ~/buckets/b1/exp/HT2900  que corresponde a su Google Drive\n",
    "<br>HT significa Hyperparameter Tuning\n",
    "<br>El Grid Search es un método de fuerza bruta de un altísimo costo computacional.\n",
    "<br>Queremos ver si es posible crear un algoritmo de optimización de hiperparámetros que se ahorre recorrer ciertas porciones muy malas del espacio de búsqueda. Algo del estilo “cada vez que pruebo una combinación de hiperparámetros donde  cp > 1 , la ganancia es muy mala, con lo cual ni vale la pena perder el tiempo explorando en esa region”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaVgMu4tPwyB"
   },
   "source": [
    "<br>Levante el archivo de salida gridsearch.txt  a una planilla tipo Excel y analícelo detenidamente\n",
    "<br>Ordene por ganancia_mean descendente\n",
    "<br>\n",
    "<br>El de mayor ganancia_mean  decimos que es el primero del ranking\n",
    "En el channel  #Labo1R-Tarea Hogar 02 , topic Analisis Grid Search   intente contestar estas preguntas:\n",
    "\n",
    "* ¿Qué combinaciones de hiperparámetros poseen una ganancia muy buena?\n",
    "* ¿Hay algun hiperparámetro que para cierto valor siempre genera una ganancia muy mala, a independientemente de lo que valgan los otros hiperparámetros ?\n",
    "* ¿Que combinaciones de hiperparámetros es pésima y hubiera sido bueno ahorrarse esas corridas ?\n",
    "\n",
    "( tiempo estimado 30 minutos, dificultad media )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
